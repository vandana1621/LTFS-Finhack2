{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import date\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "import lightgbm as lgb\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((80402, 6), (180, 3), (180, 4))"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"train_fwYjLYX.csv\", parse_dates=['application_date'])\n",
    "test = pd.read_csv(\"test_1eLl9Yf.csv\", parse_dates=['application_date'])\n",
    "submission = pd.read_csv(\"sample_submission_IIzFVsf.csv\", parse_dates=['application_date'])\n",
    "train.shape,test.shape,submission.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.drop(['id'], axis=1, inplace=True)\n",
    "train = train.sort_values('application_date').reset_index(drop = True)\n",
    "test = test.sort_values('application_date').reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Timestamp('2017-04-01 00:00:00'), Timestamp('2019-07-23 00:00:00'))"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.application_date.min(), train.application_date.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Timestamp('2019-07-06 00:00:00'), Timestamp('2019-10-24 00:00:00'))"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.application_date.min(), test.application_date.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined df shape:(1830, 4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "264"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_func = {'case_count': ['sum']}\n",
    "agg_name = train.groupby(['segment','application_date']).agg(agg_func)\n",
    "agg_name.columns = [ 'SA_' + ('_'.join(col).strip()) for col in agg_name.columns.values]\n",
    "agg_name.reset_index(inplace=True)\n",
    "train = train.merge(agg_name, on=['segment','application_date'], how='left')\n",
    "del agg_name\n",
    "train.drop(['branch_id','state','zone','case_count'], axis=1, inplace=True)\n",
    "train = train.rename(columns={'SA_case_count_sum': 'case_count'})\n",
    "train.drop_duplicates(keep='first', inplace=True)\n",
    "train = train.sort_values('application_date').reset_index(drop = True)\n",
    "# df = train.append(test, ignore_index=True,sort=False)\n",
    "\n",
    "train['train_or_test'] = 'train'\n",
    "test['train_or_test'] = 'test'\n",
    "df = pd.concat([train,test], sort=False)\n",
    "print('Combined df shape:{}'.format(df.shape))\n",
    "del train, test\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>application_date</th>\n",
       "      <th>segment</th>\n",
       "      <th>case_count</th>\n",
       "      <th>train_or_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-04-01</td>\n",
       "      <td>1</td>\n",
       "      <td>299.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-04-01</td>\n",
       "      <td>2</td>\n",
       "      <td>897.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  application_date  segment  case_count train_or_test\n",
       "0       2017-04-01        1       299.0         train\n",
       "1       2017-04-01        2       897.0         train"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>application_date</th>\n",
       "      <th>segment</th>\n",
       "      <th>case_count</th>\n",
       "      <th>train_or_test</th>\n",
       "      <th>dayofmonth</th>\n",
       "      <th>dayofyear</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>weekofyear</th>\n",
       "      <th>is_month_start</th>\n",
       "      <th>is_month_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-04-01</td>\n",
       "      <td>1</td>\n",
       "      <td>299.0</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "      <td>91</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2017</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-04-01</td>\n",
       "      <td>2</td>\n",
       "      <td>897.0</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "      <td>91</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2017</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-04-02</td>\n",
       "      <td>2</td>\n",
       "      <td>605.0</td>\n",
       "      <td>train</td>\n",
       "      <td>2</td>\n",
       "      <td>92</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>2017</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-04-03</td>\n",
       "      <td>1</td>\n",
       "      <td>42.0</td>\n",
       "      <td>train</td>\n",
       "      <td>3</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2017</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-04-03</td>\n",
       "      <td>2</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>train</td>\n",
       "      <td>3</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2017</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  application_date  segment  case_count train_or_test  dayofmonth  dayofyear  \\\n",
       "0       2017-04-01        1       299.0         train           1         91   \n",
       "1       2017-04-01        2       897.0         train           1         91   \n",
       "2       2017-04-02        2       605.0         train           2         92   \n",
       "3       2017-04-03        1        42.0         train           3         93   \n",
       "4       2017-04-03        2      2016.0         train           3         93   \n",
       "\n",
       "   dayofweek  month  year  weekofyear  is_month_start  is_month_end  \n",
       "0          5      4  2017          13               1             0  \n",
       "1          5      4  2017          13               1             0  \n",
       "2          6      4  2017          13               0             0  \n",
       "3          0      4  2017          14               0             0  \n",
       "4          0      4  2017          14               0             0  "
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extracting application_date features\n",
    "df['dayofmonth'] = df.application_date.dt.day\n",
    "df['dayofyear'] = df.application_date.dt.dayofyear\n",
    "df['dayofweek'] = df.application_date.dt.dayofweek\n",
    "df['month'] = df.application_date.dt.month\n",
    "df['year'] = df.application_date.dt.year\n",
    "df['weekofyear'] = df.application_date.dt.weekofyear\n",
    "df['is_month_start'] = (df.application_date.dt.is_month_start).astype(int)\n",
    "df['is_month_end'] = (df.application_date.dt.is_month_end).astype(int)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>application_date</th>\n",
       "      <th>segment</th>\n",
       "      <th>case_count</th>\n",
       "      <th>train_or_test</th>\n",
       "      <th>dayofmonth</th>\n",
       "      <th>dayofyear</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>weekofyear</th>\n",
       "      <th>is_month_start</th>\n",
       "      <th>is_month_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-04-01</td>\n",
       "      <td>1</td>\n",
       "      <td>299.0</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "      <td>91</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2017</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-04-03</td>\n",
       "      <td>1</td>\n",
       "      <td>42.0</td>\n",
       "      <td>train</td>\n",
       "      <td>3</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2017</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  application_date  segment  case_count train_or_test  dayofmonth  dayofyear  \\\n",
       "0       2017-04-01        1       299.0         train           1         91   \n",
       "3       2017-04-03        1        42.0         train           3         93   \n",
       "\n",
       "   dayofweek  month  year  weekofyear  is_month_start  is_month_end  \n",
       "0          5      4  2017          13               1             0  \n",
       "3          0      4  2017          14               0             0  "
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by=['segment','application_date'], axis=0, inplace=True)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features constructed from previous case_count values\n",
    "\n",
    "# Creating case_count lag features\n",
    "def create_case_count_lag_feats(df, gpby_cols, target_col, lags):\n",
    "    gpby = df.groupby(gpby_cols)\n",
    "    for i in lags:\n",
    "        df['_'.join([target_col, 'lag', str(i)])] = \\\n",
    "                gpby[target_col].shift(i).values + np.random.normal(scale=1.6, size=(len(df),))\n",
    "    return df\n",
    "\n",
    "# Creating case_count rolling mean features\n",
    "def create_case_count_rmean_feats(df, gpby_cols, target_col, windows, min_periods=2, \n",
    "                             shift=1, win_type=None):\n",
    "    gpby = df.groupby(gpby_cols)\n",
    "    for w in windows:\n",
    "        df['_'.join([target_col, 'rmean', str(w)])] = \\\n",
    "            gpby[target_col].shift(shift).rolling(window=w, \n",
    "                                                  min_periods=min_periods,\n",
    "                                                  win_type=win_type).mean().values + np.random.normal(scale=1.6, size=(len(df),))\n",
    "    return df\n",
    "\n",
    "# Creating case_count exponentially weighted mean features\n",
    "def create_case_count_ewm_feats(df, gpby_cols, target_col, alpha=[0.9], shift=[1]):\n",
    "    gpby = df.groupby(gpby_cols)\n",
    "    for a in alpha:\n",
    "        for s in shift:\n",
    "            df['_'.join([target_col, 'lag', str(s), 'ewm', str(a)])] = \\\n",
    "                gpby[target_col].shift(s).ewm(alpha=a).mean().values + np.random.normal(scale=1.6, size=(len(df),))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OHE of categorical features\n",
    "\n",
    "def one_hot_encoder(df, ohe_cols=['dayofmonth','dayofweek','month','weekofyear']):\n",
    "    '''\n",
    "    One-Hot Encoder function\n",
    "    '''\n",
    "    print('Creating OHE features..\\nOld df shape:{}'.format(df.shape))\n",
    "    df = pd.get_dummies(df, columns=ohe_cols)\n",
    "    print('New df shape:{}'.format(df.shape))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>application_date</th>\n",
       "      <th>segment</th>\n",
       "      <th>case_count</th>\n",
       "      <th>train_or_test</th>\n",
       "      <th>dayofmonth</th>\n",
       "      <th>dayofyear</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>weekofyear</th>\n",
       "      <th>is_month_start</th>\n",
       "      <th>is_month_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-04-01</td>\n",
       "      <td>1</td>\n",
       "      <td>5.703782</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "      <td>91</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2017</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-04-03</td>\n",
       "      <td>1</td>\n",
       "      <td>3.761200</td>\n",
       "      <td>train</td>\n",
       "      <td>3</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2017</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  application_date  segment  case_count train_or_test  dayofmonth  dayofyear  \\\n",
       "0       2017-04-01        1    5.703782         train           1         91   \n",
       "3       2017-04-03        1    3.761200         train           3         93   \n",
       "\n",
       "   dayofweek  month  year  weekofyear  is_month_start  is_month_end  \n",
       "0          5      4  2017          13               1             0  \n",
       "3          0      4  2017          14               0             0  "
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting case_count to log(1+case_count)\n",
    "df['case_count'] = np.log1p(df.case_count.values)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (1428, 12)\n",
      "Validation shape: (222, 12)\n",
      "No train shape: (0, 12)\n",
      "Test shape: (180, 12)\n"
     ]
    }
   ],
   "source": [
    "# Time-based Validation set\n",
    "\n",
    "# For validation to keep months also identical to test set we can choose period (same of 2018) as the validation set.\n",
    "\n",
    "masked_series = (df['application_date'] >= '2018-07-06') & (df['application_date'] <= '2018-10-24')\n",
    "masked_series2 = (df['application_date'] < '2018-07-06') & (df['application_date'] > '2018-10-24')\n",
    "df.loc[(masked_series), 'train_or_test'] = 'val'\n",
    "df.loc[(masked_series2), 'train_or_test'] = 'no_train'\n",
    "print('Train shape: {}'.format(df.loc[df.train_or_test=='train',:].shape))\n",
    "print('Validation shape: {}'.format(df.loc[df.train_or_test=='val',:].shape))\n",
    "print('No train shape: {}'.format(df.loc[df.train_or_test=='no_train',:].shape))\n",
    "print('Test shape: {}'.format(df.loc[df.train_or_test=='test',:].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating OHE features..\n",
      "Old df shape:(1650, 84)\n",
      "New df shape:(1650, 101)\n",
      "Train shape:(1428, 101), Val shape:(222, 101)\n"
     ]
    }
   ],
   "source": [
    "# Model Validation\n",
    "\n",
    "# Converting case_count of validation period to nan so as to resemble test period\n",
    "train = df.loc[df.train_or_test.isin(['train','val']), :]\n",
    "Y_val = train.loc[train.train_or_test=='val', 'case_count'].values.reshape((-1))\n",
    "Y_train = train.loc[train.train_or_test=='train', 'case_count'].values.reshape((-1))\n",
    "train.loc[train.train_or_test=='val', 'case_count'] = np.nan\n",
    "\n",
    "# # Creating case_count lag, rolling mean, rolling median, ohe features of the above train set\n",
    "train = create_case_count_lag_feats(train, gpby_cols=['segment'], target_col='case_count', \n",
    "#                                lags=[91,98,105,112,119,126,133,140,147,154,161,168,175,182,364,546,728])\n",
    "                                    lags=[91,98,105,112,119,126,182,364,546,728])\n",
    "\n",
    "train = create_case_count_rmean_feats(train, gpby_cols=['segment'], \n",
    "                                 target_col='case_count', windows=[364,546], \n",
    "                                 min_periods=10, win_type='triang') #98,119,91,182,\n",
    "\n",
    "\n",
    "train = create_case_count_ewm_feats(train, gpby_cols=['segment'], \n",
    "                               target_col='case_count', \n",
    "                               alpha=[0.95, 0.9, 0.8, 0.7, 0.6, 0.5], \n",
    "                               shift=[91,98,105,112,119,126,182,364,546,728])\n",
    "\n",
    "\n",
    "# One-Hot Encoding \n",
    "train = one_hot_encoder(train, ohe_cols=['dayofweek','month'])\n",
    "\n",
    "# Final train and val datasets\n",
    "val = train.loc[train.train_or_test=='val', :]\n",
    "train = train.loc[train.train_or_test=='train', :]\n",
    "print('Train shape:{}, Val shape:{}'.format(train.shape, val.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of training features: 96 \n",
      "And they are:['segment', 'dayofmonth', 'dayofyear', 'weekofyear', 'is_month_end', 'case_count_lag_91', 'case_count_lag_98', 'case_count_lag_105', 'case_count_lag_112', 'case_count_lag_119', 'case_count_lag_126', 'case_count_lag_182', 'case_count_lag_364', 'case_count_lag_546', 'case_count_lag_728', 'case_count_rmean_364', 'case_count_rmean_546', 'case_count_lag_91_ewm_0.95', 'case_count_lag_98_ewm_0.95', 'case_count_lag_105_ewm_0.95', 'case_count_lag_112_ewm_0.95', 'case_count_lag_119_ewm_0.95', 'case_count_lag_126_ewm_0.95', 'case_count_lag_182_ewm_0.95', 'case_count_lag_364_ewm_0.95', 'case_count_lag_546_ewm_0.95', 'case_count_lag_728_ewm_0.95', 'case_count_lag_91_ewm_0.9', 'case_count_lag_98_ewm_0.9', 'case_count_lag_105_ewm_0.9', 'case_count_lag_112_ewm_0.9', 'case_count_lag_119_ewm_0.9', 'case_count_lag_126_ewm_0.9', 'case_count_lag_182_ewm_0.9', 'case_count_lag_364_ewm_0.9', 'case_count_lag_546_ewm_0.9', 'case_count_lag_728_ewm_0.9', 'case_count_lag_91_ewm_0.8', 'case_count_lag_98_ewm_0.8', 'case_count_lag_105_ewm_0.8', 'case_count_lag_112_ewm_0.8', 'case_count_lag_119_ewm_0.8', 'case_count_lag_126_ewm_0.8', 'case_count_lag_182_ewm_0.8', 'case_count_lag_364_ewm_0.8', 'case_count_lag_546_ewm_0.8', 'case_count_lag_728_ewm_0.8', 'case_count_lag_91_ewm_0.7', 'case_count_lag_98_ewm_0.7', 'case_count_lag_105_ewm_0.7', 'case_count_lag_112_ewm_0.7', 'case_count_lag_119_ewm_0.7', 'case_count_lag_126_ewm_0.7', 'case_count_lag_182_ewm_0.7', 'case_count_lag_364_ewm_0.7', 'case_count_lag_546_ewm_0.7', 'case_count_lag_728_ewm_0.7', 'case_count_lag_91_ewm_0.6', 'case_count_lag_98_ewm_0.6', 'case_count_lag_105_ewm_0.6', 'case_count_lag_112_ewm_0.6', 'case_count_lag_119_ewm_0.6', 'case_count_lag_126_ewm_0.6', 'case_count_lag_182_ewm_0.6', 'case_count_lag_364_ewm_0.6', 'case_count_lag_546_ewm_0.6', 'case_count_lag_728_ewm_0.6', 'case_count_lag_91_ewm_0.5', 'case_count_lag_98_ewm_0.5', 'case_count_lag_105_ewm_0.5', 'case_count_lag_112_ewm_0.5', 'case_count_lag_119_ewm_0.5', 'case_count_lag_126_ewm_0.5', 'case_count_lag_182_ewm_0.5', 'case_count_lag_364_ewm_0.5', 'case_count_lag_546_ewm_0.5', 'case_count_lag_728_ewm_0.5', 'dayofweek_0', 'dayofweek_1', 'dayofweek_2', 'dayofweek_3', 'dayofweek_4', 'dayofweek_5', 'dayofweek_6', 'month_1', 'month_2', 'month_3', 'month_4', 'month_5', 'month_6', 'month_7', 'month_8', 'month_9', 'month_10', 'month_11', 'month_12']\n"
     ]
    }
   ],
   "source": [
    "avoid_cols = ['application_date', 'case_count', 'train_or_test', 'id', 'year','is_month_start']\n",
    "cols = [col for col in train.columns if col not in avoid_cols]\n",
    "print('No of training features: {} \\nAnd they are:{}'.format(len(cols), cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mape(preds, target):\n",
    "    '''\n",
    "    Function to calculate MAPE\n",
    "    '''\n",
    "    n = len(preds)\n",
    "    masked_arr = ~((preds==0)&(target==0))\n",
    "    preds, target = preds[masked_arr], target[masked_arr]\n",
    "    num = target-preds\n",
    "    denom = target\n",
    "    mape_val = np.mean(np.abs(num / denom)) * 100\n",
    "    return mape_val\n",
    "\n",
    "def lgbm_mape(preds, train_data):\n",
    "    '''\n",
    "    Custom Evaluation Function for LGBM\n",
    "    '''\n",
    "    labels = train_data.get_label()\n",
    "    mape_val = mape(np.expm1(preds), np.expm1(labels))\n",
    "    return 'MAPE', mape_val, False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightGBM parameters\n",
    "lgb_params = {'task':'train', 'boosting_type':'gbdt', 'objective':'mape', \n",
    "              'learning_rate': 0.02, 'verbose': 0, 'num_leaves': 62,\n",
    "              'num_boost_round':30000, 'early_stopping_rounds':2000, 'nthread':-1, 'random_state':0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating lgbtrain & lgbval\n",
    "lgbtrain = lgb.Dataset(data=train.loc[:,cols].values, label=Y_train, \n",
    "                       feature_name=cols)\n",
    "lgbval = lgb.Dataset(data=val.loc[:,cols].values, label=Y_val, \n",
    "                     reference=lgbtrain, feature_name=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgb_validation(params, lgbtrain, lgbval, X_val, Y_val, verbose_eval):\n",
    "    t0 = time.time()\n",
    "    evals_result = {}\n",
    "    model = lgb.train(params, lgbtrain, num_boost_round=params['num_boost_round'], \n",
    "                      valid_sets=[lgbtrain, lgbval], feval=lgbm_mape, \n",
    "                      early_stopping_rounds=params['early_stopping_rounds'], \n",
    "                      evals_result=evals_result, verbose_eval=verbose_eval)\n",
    "    print(model.best_iteration)\n",
    "    print('Total time taken to build the model: ', (time.time()-t0)/60, 'minutes!!')\n",
    "    pred_Y_val = model.predict(X_val, num_iteration=model.best_iteration)\n",
    "    pred_Y_val = np.expm1(pred_Y_val)\n",
    "    Y_val = np.expm1(Y_val)\n",
    "    val_df = pd.DataFrame(columns=['true_Y_val','pred_Y_val'])\n",
    "    val_df['pred_Y_val'] = pred_Y_val\n",
    "    val_df['true_Y_val'] = Y_val\n",
    "    print(val_df.shape)\n",
    "    print(val_df.head(5))\n",
    "    print('MAPE for validation data is:{}'.format(mape(pred_Y_val, Y_val)))\n",
    "    return model, val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 2000 rounds.\n",
      "[500]\ttraining's mape: 0.0261623\ttraining's MAPE: 22.8973\tvalid_1's mape: 0.0460621\tvalid_1's MAPE: 50.6978\n",
      "[1000]\ttraining's mape: 0.0229222\ttraining's MAPE: 19.1855\tvalid_1's mape: 0.046194\tvalid_1's MAPE: 50.648\n",
      "[1500]\ttraining's mape: 0.0223243\ttraining's MAPE: 17.6642\tvalid_1's mape: 0.0460103\tvalid_1's MAPE: 49.9977\n",
      "[2000]\ttraining's mape: 0.0230312\ttraining's MAPE: 17.3115\tvalid_1's mape: 0.0473784\tvalid_1's MAPE: 51.8376\n",
      "[2500]\ttraining's mape: 0.0226699\ttraining's MAPE: 15.8324\tvalid_1's mape: 0.0476591\tvalid_1's MAPE: 51.2734\n",
      "[3000]\ttraining's mape: 0.022277\ttraining's MAPE: 15.3651\tvalid_1's mape: 0.0476116\tvalid_1's MAPE: 51.4516\n",
      "Early stopping, best iteration is:\n",
      "[1429]\ttraining's mape: 0.0215806\ttraining's MAPE: 17.489\tvalid_1's mape: 0.0459044\tvalid_1's MAPE: 49.8886\n",
      "1429\n",
      "Total time taken to build the model:  1.5161173423131307 minutes!!\n",
      "(222, 2)\n",
      "   true_Y_val   pred_Y_val\n",
      "0      2890.0  1782.688185\n",
      "1      2320.0  1722.524624\n",
      "2      1301.0   869.680925\n",
      "3      3561.0  2999.185812\n",
      "4      3062.0  2907.323155\n",
      "MAPE for validation data is:49.88864968099783\n"
     ]
    }
   ],
   "source": [
    "# Training lightgbm model and validating\n",
    "model, val_df = lgb_validation(lgb_params, lgbtrain, lgbval, val.loc[:,cols].values, \n",
    "                               Y_val, verbose_eval=500)\n",
    "# 49.88 1429"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features importance...\n",
      "Top 25 features:\n",
      "                         feature  split      gain\n",
      "1                    dayofmonth   3600  6.533533\n",
      "60   case_count_lag_112_ewm_0.6   1541  2.644944\n",
      "13           case_count_lag_546    827  2.366966\n",
      "17   case_count_lag_91_ewm_0.95   1364  2.358652\n",
      "8            case_count_lag_112   1194  2.230805\n",
      "30   case_count_lag_112_ewm_0.9   1195  2.103275\n",
      "15         case_count_rmean_364   2305  2.045164\n",
      "70   case_count_lag_112_ewm_0.5   1219  2.033752\n",
      "0                       segment    195  2.028177\n",
      "40   case_count_lag_112_ewm_0.8   1148  2.026639\n",
      "20  case_count_lag_112_ewm_0.95   1176  1.942020\n",
      "2                     dayofyear   2161  1.907056\n",
      "16         case_count_rmean_546   1868  1.661541\n",
      "41   case_count_lag_119_ewm_0.8   1122  1.555234\n",
      "65   case_count_lag_546_ewm_0.6    714  1.471248\n",
      "45   case_count_lag_546_ewm_0.8    844  1.461482\n",
      "29   case_count_lag_105_ewm_0.9   1011  1.461074\n",
      "5             case_count_lag_91   1346  1.437954\n",
      "6             case_count_lag_98   1255  1.415010\n",
      "33   case_count_lag_182_ewm_0.9   1149  1.414887\n",
      "55   case_count_lag_546_ewm_0.7    646  1.404053\n",
      "63   case_count_lag_182_ewm_0.6   1138  1.357587\n",
      "47    case_count_lag_91_ewm_0.7   1240  1.336415\n",
      "7            case_count_lag_105   1081  1.325047\n",
      "10           case_count_lag_126   1049  1.222737\n",
      "52   case_count_lag_126_ewm_0.7   1015  1.202483\n",
      "57    case_count_lag_91_ewm_0.6    992  1.176990\n",
      "58    case_count_lag_98_ewm_0.6   1029  1.170268\n",
      "9            case_count_lag_119   1061  1.165577\n",
      "28    case_count_lag_98_ewm_0.9    917  1.161209\n",
      "37    case_count_lag_91_ewm_0.8   1077  1.160397\n",
      "73   case_count_lag_182_ewm_0.5   1066  1.156212\n",
      "11           case_count_lag_182   1143  1.153706\n",
      "27    case_count_lag_91_ewm_0.9   1097  1.153612\n",
      "31   case_count_lag_119_ewm_0.9   1008  1.148754\n",
      "64   case_count_lag_364_ewm_0.6    844  1.148070\n",
      "53   case_count_lag_182_ewm_0.7   1072  1.146184\n",
      "74   case_count_lag_364_ewm_0.5    840  1.143179\n",
      "51   case_count_lag_119_ewm_0.7    967  1.137028\n",
      "21  case_count_lag_119_ewm_0.95   1002  1.106814\n",
      "59   case_count_lag_105_ewm_0.6    915  1.081870\n",
      "23  case_count_lag_182_ewm_0.95   1010  1.077692\n",
      "32   case_count_lag_126_ewm_0.9    980  1.074221\n",
      "69   case_count_lag_105_ewm_0.5    941  1.072427\n",
      "54   case_count_lag_364_ewm_0.7    866  1.058066\n",
      "38    case_count_lag_98_ewm_0.8    873  1.050166\n",
      "48    case_count_lag_98_ewm_0.7    953  1.046264\n",
      "61   case_count_lag_119_ewm_0.6    989  1.042627\n",
      "71   case_count_lag_119_ewm_0.5    945  1.041223\n",
      "68    case_count_lag_98_ewm_0.5    955  1.034625\n"
     ]
    }
   ],
   "source": [
    "# Let's see top 25 features as identified by the lightgbm model.\n",
    "print(\"Features importance...\")\n",
    "gain = model.feature_importance('gain')\n",
    "feat_imp = pd.DataFrame({'feature':model.feature_name(), \n",
    "                         'split':model.feature_importance('split'), \n",
    "                         'gain':100 * gain / gain.sum()}).sort_values('gain', ascending=False)\n",
    "print('Top 25 features:\\n', feat_imp.head(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features importance...\n",
      "Top 25 features:\n",
      "                         feature  split      gain\n",
      "1                    dayofmonth   3600  6.533533\n",
      "15         case_count_rmean_364   2305  2.045164\n",
      "2                     dayofyear   2161  1.907056\n",
      "16         case_count_rmean_546   1868  1.661541\n",
      "60   case_count_lag_112_ewm_0.6   1541  2.644944\n",
      "17   case_count_lag_91_ewm_0.95   1364  2.358652\n",
      "5             case_count_lag_91   1346  1.437954\n",
      "6             case_count_lag_98   1255  1.415010\n",
      "47    case_count_lag_91_ewm_0.7   1240  1.336415\n",
      "70   case_count_lag_112_ewm_0.5   1219  2.033752\n",
      "30   case_count_lag_112_ewm_0.9   1195  2.103275\n",
      "8            case_count_lag_112   1194  2.230805\n",
      "20  case_count_lag_112_ewm_0.95   1176  1.942020\n",
      "33   case_count_lag_182_ewm_0.9   1149  1.414887\n",
      "40   case_count_lag_112_ewm_0.8   1148  2.026639\n",
      "11           case_count_lag_182   1143  1.153706\n",
      "63   case_count_lag_182_ewm_0.6   1138  1.357587\n",
      "41   case_count_lag_119_ewm_0.8   1122  1.555234\n",
      "27    case_count_lag_91_ewm_0.9   1097  1.153612\n",
      "7            case_count_lag_105   1081  1.325047\n",
      "37    case_count_lag_91_ewm_0.8   1077  1.160397\n",
      "53   case_count_lag_182_ewm_0.7   1072  1.146184\n",
      "73   case_count_lag_182_ewm_0.5   1066  1.156212\n",
      "9            case_count_lag_119   1061  1.165577\n",
      "10           case_count_lag_126   1049  1.222737\n",
      "58    case_count_lag_98_ewm_0.6   1029  1.170268\n",
      "52   case_count_lag_126_ewm_0.7   1015  1.202483\n",
      "29   case_count_lag_105_ewm_0.9   1011  1.461074\n",
      "23  case_count_lag_182_ewm_0.95   1010  1.077692\n",
      "31   case_count_lag_119_ewm_0.9   1008  1.148754\n",
      "..                          ...    ...       ...\n",
      "55   case_count_lag_546_ewm_0.7    646  1.404053\n",
      "25  case_count_lag_546_ewm_0.95    643  0.763739\n",
      "35   case_count_lag_546_ewm_0.9    636  0.731252\n",
      "56   case_count_lag_728_ewm_0.7    631  0.582919\n",
      "66   case_count_lag_728_ewm_0.6    618  0.655383\n",
      "75   case_count_lag_546_ewm_0.5    618  0.628586\n",
      "76   case_count_lag_728_ewm_0.5    607  0.545976\n",
      "14           case_count_lag_728    451  0.611762\n",
      "83                  dayofweek_6    424  0.808609\n",
      "0                       segment    195  2.028177\n",
      "3                    weekofyear    178  0.218712\n",
      "82                  dayofweek_5    161  0.347573\n",
      "87                      month_4    132  0.204761\n",
      "88                      month_5    101  0.096277\n",
      "89                      month_6     97  0.083960\n",
      "4                  is_month_end     85  0.406856\n",
      "77                  dayofweek_0     69  0.098743\n",
      "80                  dayofweek_3     60  0.072921\n",
      "79                  dayofweek_2     53  0.056415\n",
      "81                  dayofweek_4     42  0.043929\n",
      "86                      month_3     39  0.066377\n",
      "94                     month_11     35  0.057902\n",
      "78                  dayofweek_1     27  0.033018\n",
      "91                      month_8     19  0.049194\n",
      "90                      month_7     10  0.008238\n",
      "84                      month_1      6  0.007346\n",
      "85                      month_2      5  0.006643\n",
      "93                     month_10      5  0.005891\n",
      "92                      month_9      4  0.006483\n",
      "95                     month_12      0  0.000000\n",
      "\n",
      "[96 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Let's see top 25 features as identified by the lightgbm model.\n",
    "print(\"Features importance...\")\n",
    "gain = model.feature_importance('gain')\n",
    "feat_imp = pd.DataFrame({'feature':model.feature_name(), \n",
    "                         'split':model.feature_importance('split'), \n",
    "                         'gain':100 * gain / gain.sum()}).sort_values('split', ascending=False)\n",
    "print('Top 25 features:\\n', feat_imp.head(500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating OHE features..\n",
      "Old df shape:(1830, 84)\n",
      "New df shape:(1830, 101)\n",
      "Train shape:(1650, 101), Test shape:(180, 101)\n"
     ]
    }
   ],
   "source": [
    "# Creating case_count lag, rolling mean, rolling median, ohe features of the above train set\n",
    "df_whole = create_case_count_lag_feats(df, gpby_cols=['segment'], target_col='case_count', \n",
    "                                  lags=[91,98,105,112,119,126,182,364,546,728])\n",
    "\n",
    "df_whole = create_case_count_rmean_feats(df_whole, gpby_cols=['segment'], \n",
    "                                    target_col='case_count', windows=[364,546], \n",
    "                                    min_periods=10, win_type='triang')\n",
    "\n",
    "df_whole = create_case_count_ewm_feats(df_whole, gpby_cols=['segment'], target_col='case_count', \n",
    "                                  alpha=[0.95, 0.9, 0.8, 0.7, 0.6, 0.5], \n",
    "                                  shift=[91,98,105,112,119,126,182,364,546,728])\n",
    "\n",
    "\n",
    "\n",
    "# One-Hot Encoding\n",
    "df_whole = one_hot_encoder(df_whole, ohe_cols=['dayofweek','month']) \n",
    "\n",
    "# Final train and test datasets\n",
    "test = df_whole.loc[df_whole.train_or_test=='test', :]\n",
    "train = df_whole.loc[~(df_whole.train_or_test=='test'), :]\n",
    "print('Train shape:{}, Test shape:{}'.format(train.shape, test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:05<00:00,  2.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1830, 9)\n",
      "(1650, 108) (180, 108)\n"
     ]
    }
   ],
   "source": [
    "from fbprophet import Prophet\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "import datetime as dt\n",
    "\n",
    "def create_prophet_features(train):\n",
    "    \"\"\"\n",
    "    Train a seperate fbprophet model on each segment.\n",
    "    Use the results as features used by the final model\n",
    "    \"\"\"\n",
    "    grouped = train.groupby(['segment'])\n",
    "    prophet_results = []\n",
    "    for i, d in tqdm(grouped):\n",
    "        m = Prophet(uncertainty_samples=100, daily_seasonality=False)\n",
    "        m.fit(d.rename(columns={'application_date': 'ds', 'case_count': 'y'}))\n",
    "        future = m.make_future_dataframe(periods=90)\n",
    "        forecast = m.predict(future)\n",
    "        forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail()\n",
    "        forecast['segment'] = i\n",
    "        prophet_results.append(forecast)\n",
    "    prophet_features = pd.concat(prophet_results)\n",
    "    prophet_features = prophet_features.rename(columns={'ds': 'application_date'})\n",
    "    prophet_features.to_csv('prophet_results.csv')\n",
    "    return prophet_features\n",
    "\n",
    "\n",
    "pro = create_prophet_features(train)\n",
    "corr_col = ['multiplicative_terms','multiplicative_terms_lower','multiplicative_terms_upper',\n",
    "            'additive_terms_lower','additive_terms_upper','weekly_lower','weekly_upper',\n",
    "           'yearly_lower','yearly_upper','trend_lower','trend_upper']\n",
    "final_cols = [col for col in pro.columns if col not in corr_col]\n",
    "print(pro[final_cols].shape)\n",
    "pro[final_cols].reset_index(drop=True,inplace=True)\n",
    "\n",
    "train = train.merge(pro[final_cols], on=['segment','application_date'], how='left')\n",
    "test = test.merge(pro[final_cols], on=['segment','application_date'], how='left')\n",
    "print(train.shape,test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightGBM parameters\n",
    "lgb_params = {'task':'train', 'boosting_type':'gbdt', 'objective':'mape', \n",
    "              'metric': 'mape', 'learning_rate': 0.02, 'verbose': 0, 'num_leaves': 62,\n",
    "              'num_boost_round':model.best_iteration*1.2,'nthread':-1, 'random_state':0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightGBM dataset\n",
    "lgbtrain_all = lgb.Dataset(data=train.loc[:,cols].values, \n",
    "                           label=train.loc[:,'case_count'].values.reshape((-1,)), \n",
    "                           feature_name=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgb_train(params, lgbtrain_all, X_test, num_round):\n",
    "    t0 = time.time()\n",
    "    model = lgb.train(params, lgbtrain_all, num_boost_round=num_round, feval=lgbm_mape)\n",
    "    test_preds = model.predict(X_test, num_iteration=num_round)\n",
    "    print('Total time taken in model training: ', (time.time()-t0)/60, 'minutes!')\n",
    "    return model, test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time taken in model training:  0.8421529690424602 minutes!\n",
      "test_preds shape:(180,)\n"
     ]
    }
   ],
   "source": [
    "# Training lgb model on whole data(train+val)\n",
    "lgb_model, test_preds = lgb_train(lgb_params, lgbtrain_all, test.loc[:,cols].values, model.best_iteration)\n",
    "print('test_preds shape:{}'.format(test_preds.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['case_count'] = np.expm1(test_preds)\n",
    "submission.to_csv('lgbm_V30.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
