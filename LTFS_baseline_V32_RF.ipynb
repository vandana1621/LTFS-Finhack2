{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import date\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((80402, 6), (180, 3), (180, 4))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"train_fwYjLYX.csv\", parse_dates=['application_date'])\n",
    "test = pd.read_csv(\"test_1eLl9Yf.csv\", parse_dates=['application_date'])\n",
    "submission = pd.read_csv(\"sample_submission_IIzFVsf.csv\", parse_dates=['application_date'])\n",
    "train.shape,test.shape,submission.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.drop(['id'], axis=1, inplace=True)\n",
    "train = train.sort_values('application_date').reset_index(drop = True)\n",
    "test = test.sort_values('application_date').reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Timestamp('2017-04-01 00:00:00'), Timestamp('2019-07-23 00:00:00'))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.application_date.min(), train.application_date.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Timestamp('2019-07-06 00:00:00'), Timestamp('2019-10-24 00:00:00'))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.application_date.min(), test.application_date.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined df shape:(1830, 4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "125"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_func = {'case_count': ['sum']}\n",
    "agg_name = train.groupby(['segment','application_date']).agg(agg_func)\n",
    "agg_name.columns = [ 'SA_' + ('_'.join(col).strip()) for col in agg_name.columns.values]\n",
    "agg_name.reset_index(inplace=True)\n",
    "train = train.merge(agg_name, on=['segment','application_date'], how='left')\n",
    "del agg_name\n",
    "train.drop(['branch_id','state','zone','case_count'], axis=1, inplace=True)\n",
    "train = train.rename(columns={'SA_case_count_sum': 'case_count'})\n",
    "train.drop_duplicates(keep='first', inplace=True)\n",
    "train = train.sort_values('application_date').reset_index(drop = True)\n",
    "# df = train.append(test, ignore_index=True,sort=False)\n",
    "\n",
    "train['train_or_test'] = 'train'\n",
    "test['train_or_test'] = 'test'\n",
    "df = pd.concat([train,test], sort=False)\n",
    "print('Combined df shape:{}'.format(df.shape))\n",
    "del train, test\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>application_date</th>\n",
       "      <th>segment</th>\n",
       "      <th>case_count</th>\n",
       "      <th>train_or_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-04-01</td>\n",
       "      <td>1</td>\n",
       "      <td>299.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-04-01</td>\n",
       "      <td>2</td>\n",
       "      <td>897.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-04-02</td>\n",
       "      <td>2</td>\n",
       "      <td>605.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-04-03</td>\n",
       "      <td>1</td>\n",
       "      <td>42.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-04-03</td>\n",
       "      <td>2</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  application_date  segment  case_count train_or_test\n",
       "0       2017-04-01        1       299.0         train\n",
       "1       2017-04-01        2       897.0         train\n",
       "2       2017-04-02        2       605.0         train\n",
       "3       2017-04-03        1        42.0         train\n",
       "4       2017-04-03        2      2016.0         train"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>application_date</th>\n",
       "      <th>segment</th>\n",
       "      <th>case_count</th>\n",
       "      <th>train_or_test</th>\n",
       "      <th>dayofmonth</th>\n",
       "      <th>dayofyear</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>weekofyear</th>\n",
       "      <th>is_month_start</th>\n",
       "      <th>is_month_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-04-01</td>\n",
       "      <td>1</td>\n",
       "      <td>299.0</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "      <td>91</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2017</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-04-01</td>\n",
       "      <td>2</td>\n",
       "      <td>897.0</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "      <td>91</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2017</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-04-02</td>\n",
       "      <td>2</td>\n",
       "      <td>605.0</td>\n",
       "      <td>train</td>\n",
       "      <td>2</td>\n",
       "      <td>92</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>2017</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-04-03</td>\n",
       "      <td>1</td>\n",
       "      <td>42.0</td>\n",
       "      <td>train</td>\n",
       "      <td>3</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2017</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-04-03</td>\n",
       "      <td>2</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>train</td>\n",
       "      <td>3</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2017</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  application_date  segment  case_count train_or_test  dayofmonth  dayofyear  \\\n",
       "0       2017-04-01        1       299.0         train           1         91   \n",
       "1       2017-04-01        2       897.0         train           1         91   \n",
       "2       2017-04-02        2       605.0         train           2         92   \n",
       "3       2017-04-03        1        42.0         train           3         93   \n",
       "4       2017-04-03        2      2016.0         train           3         93   \n",
       "\n",
       "   dayofweek  month  year  weekofyear  is_month_start  is_month_end  \n",
       "0          5      4  2017          13               1             0  \n",
       "1          5      4  2017          13               1             0  \n",
       "2          6      4  2017          13               0             0  \n",
       "3          0      4  2017          14               0             0  \n",
       "4          0      4  2017          14               0             0  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extracting application_date features\n",
    "df['dayofmonth'] = df.application_date.dt.day\n",
    "df['dayofyear'] = df.application_date.dt.dayofyear\n",
    "df['dayofweek'] = df.application_date.dt.dayofweek\n",
    "df['month'] = df.application_date.dt.month\n",
    "df['year'] = df.application_date.dt.year\n",
    "df['weekofyear'] = df.application_date.dt.weekofyear\n",
    "df['is_month_start'] = (df.application_date.dt.is_month_start).astype(int)\n",
    "df['is_month_end'] = (df.application_date.dt.is_month_end).astype(int)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>application_date</th>\n",
       "      <th>segment</th>\n",
       "      <th>case_count</th>\n",
       "      <th>train_or_test</th>\n",
       "      <th>dayofmonth</th>\n",
       "      <th>dayofyear</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>weekofyear</th>\n",
       "      <th>is_month_start</th>\n",
       "      <th>is_month_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-04-01</td>\n",
       "      <td>1</td>\n",
       "      <td>299.0</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "      <td>91</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2017</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-04-03</td>\n",
       "      <td>1</td>\n",
       "      <td>42.0</td>\n",
       "      <td>train</td>\n",
       "      <td>3</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2017</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  application_date  segment  case_count train_or_test  dayofmonth  dayofyear  \\\n",
       "0       2017-04-01        1       299.0         train           1         91   \n",
       "3       2017-04-03        1        42.0         train           3         93   \n",
       "\n",
       "   dayofweek  month  year  weekofyear  is_month_start  is_month_end  \n",
       "0          5      4  2017          13               1             0  \n",
       "3          0      4  2017          14               0             0  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by=['segment','application_date'], axis=0, inplace=True)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features constructed from previous case_count values\n",
    "\n",
    "# Creating case_count lag features\n",
    "def create_case_count_lag_feats(df, gpby_cols, target_col, lags):\n",
    "    gpby = df.groupby(gpby_cols)\n",
    "    for i in lags:\n",
    "        df['_'.join([target_col, 'lag', str(i)])] = \\\n",
    "                gpby[target_col].shift(i).values + np.random.normal(scale=1.6, size=(len(df),))\n",
    "    return df\n",
    "\n",
    "# Creating case_count rolling mean features\n",
    "def create_case_count_rmean_feats(df, gpby_cols, target_col, windows, min_periods=2, \n",
    "                             shift=1, win_type=None):\n",
    "    gpby = df.groupby(gpby_cols)\n",
    "    for w in windows:\n",
    "        df['_'.join([target_col, 'rmean',str(shift), str(w)])] = \\\n",
    "            gpby[target_col].shift(shift).rolling(window=w, \n",
    "                                                  min_periods=min_periods,\n",
    "                                                  win_type=win_type).mean().values + np.random.normal(scale=1.6, size=(len(df),))\n",
    "    return df\n",
    "\n",
    "# Creating case_count exponentially weighted mean features\n",
    "def create_case_count_ewm_feats(df, gpby_cols, target_col, alpha=[0.9], shift=[1]):\n",
    "    gpby = df.groupby(gpby_cols)\n",
    "    for a in alpha:\n",
    "        for s in shift:\n",
    "            df['_'.join([target_col, 'lag', str(s), 'ewm', str(a)])] = \\\n",
    "                gpby[target_col].shift(s).ewm(alpha=a).mean().values + np.random.normal(scale=1.6, size=(len(df),))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>application_date</th>\n",
       "      <th>segment</th>\n",
       "      <th>case_count</th>\n",
       "      <th>train_or_test</th>\n",
       "      <th>dayofmonth</th>\n",
       "      <th>dayofyear</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>weekofyear</th>\n",
       "      <th>is_month_start</th>\n",
       "      <th>is_month_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-04-01</td>\n",
       "      <td>1</td>\n",
       "      <td>5.703782</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "      <td>91</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2017</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-04-03</td>\n",
       "      <td>1</td>\n",
       "      <td>3.761200</td>\n",
       "      <td>train</td>\n",
       "      <td>3</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2017</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  application_date  segment  case_count train_or_test  dayofmonth  dayofyear  \\\n",
       "0       2017-04-01        1    5.703782         train           1         91   \n",
       "3       2017-04-03        1    3.761200         train           3         93   \n",
       "\n",
       "   dayofweek  month  year  weekofyear  is_month_start  is_month_end  \n",
       "0          5      4  2017          13               1             0  \n",
       "3          0      4  2017          14               0             0  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting case_count to log(1+case_count)\n",
    "df['case_count'] = np.log1p(df.case_count.values)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (1428, 12)\n",
      "Validation shape: (222, 12)\n",
      "No train shape: (0, 12)\n",
      "Test shape: (180, 12)\n"
     ]
    }
   ],
   "source": [
    "# Time-based Validation set\n",
    "\n",
    "# For validation to keep months also identical to test set we can choose period (same of 2018) as the validation set.\n",
    "\n",
    "masked_series = (df['application_date'] >= '2018-07-06') & (df['application_date'] <= '2018-10-24')\n",
    "masked_series2 = (df['application_date'] < '2018-07-06') & (df['application_date'] > '2018-10-24')\n",
    "df.loc[(masked_series), 'train_or_test'] = 'val'\n",
    "df.loc[(masked_series2), 'train_or_test'] = 'no_train'\n",
    "print('Train shape: {}'.format(df.loc[df.train_or_test=='train',:].shape))\n",
    "print('Validation shape: {}'.format(df.loc[df.train_or_test=='val',:].shape))\n",
    "print('No train shape: {}'.format(df.loc[df.train_or_test=='no_train',:].shape))\n",
    "print('Test shape: {}'.format(df.loc[df.train_or_test=='test',:].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape:(1428, 84), Val shape:(222, 84)\n"
     ]
    }
   ],
   "source": [
    "# Model Validation\n",
    "\n",
    "# Converting case_count of validation period to nan so as to resemble test period\n",
    "train = df.loc[df.train_or_test.isin(['train','val']), :]\n",
    "Y_val = train.loc[train.train_or_test=='val', 'case_count'].values.reshape((-1))\n",
    "Y_train = train.loc[train.train_or_test=='train', 'case_count'].values.reshape((-1))\n",
    "train.loc[train.train_or_test=='val', 'case_count'] = np.nan\n",
    "\n",
    "# # Creating case_count lag, rolling mean, rolling median, ohe features of the above train set\n",
    "train = create_case_count_lag_feats(train, gpby_cols=['segment'], target_col='case_count', \n",
    "                                    lags=[91,98,105,112,119,126,182,364,546,728])\n",
    "\n",
    "train = create_case_count_rmean_feats(train, gpby_cols=['segment'], \n",
    "                                 target_col='case_count', windows=[364,546], \n",
    "                                 min_periods=10, win_type='triang')\n",
    "\n",
    "train = create_case_count_ewm_feats(train, gpby_cols=['segment'], \n",
    "                               target_col='case_count', \n",
    "                               alpha=[0.95, 0.9, 0.8, 0.7, 0.6, 0.5], \n",
    "                               shift=[91,98,105,112,119,126,182,364,546,728])\n",
    "\n",
    "# Final train and val datasets\n",
    "val = train.loc[train.train_or_test=='val', :]\n",
    "train = train.loc[train.train_or_test=='train', :]\n",
    "print('Train shape:{}, Val shape:{}'.format(train.shape, val.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of training features: 79 \n",
      "And they are:['segment', 'dayofmonth', 'dayofyear', 'dayofweek', 'month', 'weekofyear', 'is_month_end', 'case_count_lag_91', 'case_count_lag_98', 'case_count_lag_105', 'case_count_lag_112', 'case_count_lag_119', 'case_count_lag_126', 'case_count_lag_182', 'case_count_lag_364', 'case_count_lag_546', 'case_count_lag_728', 'case_count_rmean_1_364', 'case_count_rmean_1_546', 'case_count_lag_91_ewm_0.95', 'case_count_lag_98_ewm_0.95', 'case_count_lag_105_ewm_0.95', 'case_count_lag_112_ewm_0.95', 'case_count_lag_119_ewm_0.95', 'case_count_lag_126_ewm_0.95', 'case_count_lag_182_ewm_0.95', 'case_count_lag_364_ewm_0.95', 'case_count_lag_546_ewm_0.95', 'case_count_lag_728_ewm_0.95', 'case_count_lag_91_ewm_0.9', 'case_count_lag_98_ewm_0.9', 'case_count_lag_105_ewm_0.9', 'case_count_lag_112_ewm_0.9', 'case_count_lag_119_ewm_0.9', 'case_count_lag_126_ewm_0.9', 'case_count_lag_182_ewm_0.9', 'case_count_lag_364_ewm_0.9', 'case_count_lag_546_ewm_0.9', 'case_count_lag_728_ewm_0.9', 'case_count_lag_91_ewm_0.8', 'case_count_lag_98_ewm_0.8', 'case_count_lag_105_ewm_0.8', 'case_count_lag_112_ewm_0.8', 'case_count_lag_119_ewm_0.8', 'case_count_lag_126_ewm_0.8', 'case_count_lag_182_ewm_0.8', 'case_count_lag_364_ewm_0.8', 'case_count_lag_546_ewm_0.8', 'case_count_lag_728_ewm_0.8', 'case_count_lag_91_ewm_0.7', 'case_count_lag_98_ewm_0.7', 'case_count_lag_105_ewm_0.7', 'case_count_lag_112_ewm_0.7', 'case_count_lag_119_ewm_0.7', 'case_count_lag_126_ewm_0.7', 'case_count_lag_182_ewm_0.7', 'case_count_lag_364_ewm_0.7', 'case_count_lag_546_ewm_0.7', 'case_count_lag_728_ewm_0.7', 'case_count_lag_91_ewm_0.6', 'case_count_lag_98_ewm_0.6', 'case_count_lag_105_ewm_0.6', 'case_count_lag_112_ewm_0.6', 'case_count_lag_119_ewm_0.6', 'case_count_lag_126_ewm_0.6', 'case_count_lag_182_ewm_0.6', 'case_count_lag_364_ewm_0.6', 'case_count_lag_546_ewm_0.6', 'case_count_lag_728_ewm_0.6', 'case_count_lag_91_ewm_0.5', 'case_count_lag_98_ewm_0.5', 'case_count_lag_105_ewm_0.5', 'case_count_lag_112_ewm_0.5', 'case_count_lag_119_ewm_0.5', 'case_count_lag_126_ewm_0.5', 'case_count_lag_182_ewm_0.5', 'case_count_lag_364_ewm_0.5', 'case_count_lag_546_ewm_0.5', 'case_count_lag_728_ewm_0.5']\n"
     ]
    }
   ],
   "source": [
    "avoid_cols = ['application_date', 'case_count', 'train_or_test', 'id', 'year','is_month_start']\n",
    "cols = [col for col in train.columns if col not in avoid_cols]\n",
    "print('No of training features: {} \\nAnd they are:{}'.format(len(cols), cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1428, 79), (222, 79), (1428,), (222,))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x=train[cols]\n",
    "test_x=val[cols]\n",
    "train_y=Y_train\n",
    "test_y=Y_val\n",
    "train_x.shape, test_x.shape, train_y.shape, test_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x.fillna(0,inplace=True)\n",
    "test_x.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE:  48.93419333450568\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor, BaggingRegressor\n",
    "m=RandomForestRegressor(n_estimators=100,random_state=0,max_depth= 10,criterion='mae',n_jobs=-1,oob_score= True, min_samples_leaf = 13)\n",
    "m.fit(train_x,train_y)\n",
    "preds=m.predict(test_x)\n",
    "predrf=np.expm1(preds)\n",
    "print(\"MAPE: \",(mean_absolute_percentage_error(np.expm1(test_y),predrf)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape:(1650, 84), Test shape:(180, 84)\n"
     ]
    }
   ],
   "source": [
    "# Creating case_count lag, rolling mean, rolling median, ohe features of the above train set\n",
    "df_whole = create_case_count_lag_feats(df, gpby_cols=['segment'], target_col='case_count', \n",
    "                                  lags=[91,98,105,112,119,126,182,364,546,728])\n",
    "\n",
    "df_whole = create_case_count_rmean_feats(df_whole, gpby_cols=['segment'], \n",
    "                                    target_col='case_count', windows=[364,546], \n",
    "                                    min_periods=10, win_type='triang')\n",
    "\n",
    "df_whole = create_case_count_ewm_feats(df_whole, gpby_cols=['segment'], target_col='case_count', \n",
    "                                  alpha=[0.95, 0.9, 0.8, 0.7, 0.6, 0.5], \n",
    "                               shift=[91,98,105,112,119,126,182,364,546,728])\n",
    "\n",
    "# Final train and test datasets\n",
    "test = df_whole.loc[df_whole.train_or_test=='test', :]\n",
    "train = df_whole.loc[~(df_whole.train_or_test=='test'), :]\n",
    "print('Train shape:{}, Test shape:{}'.format(train.shape, test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1650, 84), (180, 84), (1650,))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, test.shape, train['case_count'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_segment_1=train[train.segment==1]\n",
    "train_segment_1 = train_segment_1.sort_values('application_date').reset_index(drop = True)\n",
    "del train_segment_1['segment']\n",
    "\n",
    "test_segment_1=test[test.segment==1]\n",
    "test_segment_1 = test_segment_1.sort_values('application_date').reset_index(drop = True)\n",
    "del test_segment_1['segment']\n",
    "\n",
    "train_segment_2=train[train.segment==2]\n",
    "train_segment_2 = train_segment_2.sort_values('application_date').reset_index(drop = True)\n",
    "del train_segment_2['segment']\n",
    "\n",
    "test_segment_2=test[test.segment==2]\n",
    "test_segment_2 = test_segment_2.sort_values('application_date').reset_index(drop = True)\n",
    "del test_segment_2['segment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "avoid_cols = ['application_date', 'case_count', 'train_or_test', 'id', 'year','is_month_start','segment']\n",
    "cols = [col for col in train.columns if col not in avoid_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((806, 78), (87, 78), (806,))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x_segment_1=train_segment_1[cols]\n",
    "test_x_segment_1=test_segment_1[cols]\n",
    "train_y_segment_1=train_segment_1['case_count']\n",
    "train_x_segment_1.shape, test_x_segment_1.shape, train_y_segment_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((844, 78), (93, 78), (844,))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x_segment_2=train_segment_2[cols]\n",
    "test_x_segment_2=test_segment_2[cols]\n",
    "train_y_segment_2=train_segment_2['case_count']\n",
    "train_x_segment_2.shape, test_x_segment_2.shape, train_y_segment_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_segment_1.fillna(0,inplace=True)\n",
    "test_x_segment_1.fillna(0,inplace=True)\n",
    "train_x_segment_2.fillna(0,inplace=True)\n",
    "test_x_segment_2.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 300 candidates, totalling 3000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    3.7s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:   32.9s\n",
      "[Parallel(n_jobs=-1)]: Done 357 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 640 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1005 tasks      | elapsed:  7.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1450 tasks      | elapsed: 10.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1977 tasks      | elapsed: 15.5min\n",
      "[Parallel(n_jobs=-1)]: Done 2584 tasks      | elapsed: 22.9min\n",
      "[Parallel(n_jobs=-1)]: Done 3000 out of 3000 | elapsed: 26.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 26min 48s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=10, error_score=nan,\n",
       "                   estimator=RandomForestRegressor(bootstrap=True,\n",
       "                                                   ccp_alpha=0.0,\n",
       "                                                   criterion='mse',\n",
       "                                                   max_depth=None,\n",
       "                                                   max_features='auto',\n",
       "                                                   max_leaf_nodes=None,\n",
       "                                                   max_samples=None,\n",
       "                                                   min_impurity_decrease=0.0,\n",
       "                                                   min_impurity_split=None,\n",
       "                                                   min_samples_leaf=1,\n",
       "                                                   min_samples_split=2,\n",
       "                                                   min_weight_fraction_leaf=0.0,\n",
       "                                                   n_estimators=100,\n",
       "                                                   n_jobs=None, oob_score=Fal...\n",
       "                   param_distributions={'bootstrap': [True, False],\n",
       "                                        'max_depth': [10, 20, 30, 40, 50, 60,\n",
       "                                                      70, 80, 90, 100, 110,\n",
       "                                                      None],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'min_samples_leaf': [1, 2, 3, 4, 5, 6,\n",
       "                                                             7, 8, 9, 10, 11,\n",
       "                                                             12, 13, 14, 15, 16,\n",
       "                                                             17, 18, 19, 20, 21,\n",
       "                                                             22, 23, 24, 25, 26,\n",
       "                                                             27, 28, 29, 30, ...],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'n_estimators': [50, 100, 200]},\n",
       "                   pre_dispatch='2*n_jobs', random_state=0, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=2)"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 100, stop = 1200, num = 12)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 100, num = 19)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10, 15, 20]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [int(x) for x in np.linspace(start = 1, stop = 100, num = 100)]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap\n",
    "              }\n",
    "\n",
    "rf = RandomForestRegressor(criterion='mae',oob_score= True)\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 300, cv = 10, verbose=2, random_state=0, n_jobs = -1)\n",
    "rf_random.fit(train_x_segment_1,train_y_segment_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 200,\n",
       " 'min_samples_split': 5,\n",
       " 'min_samples_leaf': 13,\n",
       " 'max_features': 'auto',\n",
       " 'max_depth': 20,\n",
       " 'bootstrap': True}"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 300 candidates, totalling 3000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:   37.2s\n",
      "[Parallel(n_jobs=-1)]: Done 357 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 640 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1005 tasks      | elapsed:  6.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1450 tasks      | elapsed:  8.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1977 tasks      | elapsed: 11.3min\n",
      "[Parallel(n_jobs=-1)]: Done 2584 tasks      | elapsed: 15.4min\n",
      "[Parallel(n_jobs=-1)]: Done 3000 out of 3000 | elapsed: 17.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 17min 53s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=10, error_score=nan,\n",
       "                   estimator=RandomForestRegressor(bootstrap=True,\n",
       "                                                   ccp_alpha=0.0,\n",
       "                                                   criterion='mse',\n",
       "                                                   max_depth=None,\n",
       "                                                   max_features='auto',\n",
       "                                                   max_leaf_nodes=None,\n",
       "                                                   max_samples=None,\n",
       "                                                   min_impurity_decrease=0.0,\n",
       "                                                   min_impurity_split=None,\n",
       "                                                   min_samples_leaf=1,\n",
       "                                                   min_samples_split=2,\n",
       "                                                   min_weight_fraction_leaf=0.0,\n",
       "                                                   n_estimators=100,\n",
       "                                                   n_jobs=None, oob_score=Fal...\n",
       "                   param_distributions={'bootstrap': [True, False],\n",
       "                                        'max_depth': [10, 20, 30, 40, 50, 60,\n",
       "                                                      70, 80, 90, 100, 110,\n",
       "                                                      None],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'min_samples_leaf': [1, 2, 3, 4, 5, 6,\n",
       "                                                             7, 8, 9, 10, 11,\n",
       "                                                             12, 13, 14, 15, 16,\n",
       "                                                             17, 18, 19, 20, 21,\n",
       "                                                             22, 23, 24, 25, 26,\n",
       "                                                             27, 28, 29, 30, ...],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'n_estimators': [50, 100, 200]},\n",
       "                   pre_dispatch='2*n_jobs', random_state=0, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=2)"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 100, stop = 1200, num = 12)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 100, num = 19)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10, 15, 20]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [int(x) for x in np.linspace(start = 1, stop = 100, num = 100)]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap\n",
    "              }\n",
    "\n",
    "rf = RandomForestRegressor(criterion='mae',oob_score= True)\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 300, cv = 10, verbose=2, random_state=0, n_jobs = -1)\n",
    "rf_random.fit(train_x_segment_2,train_y_segment_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 50,\n",
       " 'min_samples_split': 5,\n",
       " 'min_samples_leaf': 3,\n",
       " 'max_features': 'auto',\n",
       " 'max_depth': 100,\n",
       " 'bootstrap': True}"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((87,), (93,))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1=RandomForestRegressor(n_estimators=1000,min_samples_split=5,min_samples_leaf = 13,max_depth= 20,n_jobs=-1,random_state=0,criterion='mae',oob_score= True)\n",
    "m2=RandomForestRegressor(n_estimators=1000,min_samples_split=5,min_samples_leaf = 3,max_depth= 100,n_jobs=-1,random_state=0,criterion='mae',oob_score= True)\n",
    "\n",
    "m1.fit(train_x_segment_1,train_y_segment_1)\n",
    "predrf_segment_1=m1.predict(test_x_segment_1)\n",
    "\n",
    "m2.fit(train_x_segment_2,train_y_segment_2)\n",
    "predrf_segment_2=m2.predict(test_x_segment_2)\n",
    "\n",
    "predrf_segment_1.shape, predrf_segment_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(180,)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predrf = np.concatenate((predrf_segment_1, predrf_segment_2), axis=None)\n",
    "predrf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['case_count'] = np.expm1(predrf)\n",
    "submission.to_csv('rf_V32.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
